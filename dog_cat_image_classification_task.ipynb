{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "f8VNxoZCiF1D"
      },
      "outputs": [],
      "source": [
        "#Using google colab for getting the dataset from google drive\n",
        "# !unzip /content/drive/MyDrive/dog_cat_dataset.zip -d /content/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Accessing the google drive from colab\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "UQtR20Agf6il"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#importing libraries\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "B2netdP0aRYt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Preprocessing and loading the dataset\n",
        "#I have not done extra preprocessing\n",
        "train_datagen = keras.preprocessing.image.ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True)\n",
        "test_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        'training_set/training_set/',\n",
        "        target_size=(227, 227),\n",
        "        batch_size=64,\n",
        "        class_mode='categorical')\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        'test_set/test_set/',\n",
        "        target_size=(227, 227),\n",
        "        batch_size=64,\n",
        "        class_mode='categorical')\n",
        "\n",
        "#Used pre-trained Inception model\n",
        "#I tried alexnet and efficientnet but I didn't get the accuracy better than Inception model\n",
        "#resized the image as per the model requirement\n",
        "model = keras.applications.InceptionV3(\n",
        "    weights=None, input_shape=(227, 227, 3), classes=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0t0bfA9jXht",
        "outputId": "470e0819-c519-4089-c23e-b14aed738efc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8005 images belonging to 2 classes.\n",
            "Found 2023 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Callbacks is used for earlystopping and for adding some functionality to train a model\n",
        "#ReduceLROnPlateau is used for reducing the learning rate from 0.001 till it satisfy the minimum learning rate till the condition\n",
        "#Adam is the best optimizer that's why I have used\n",
        "#I used batch_size 256 because I tried different different batch size but I found this performing better\n",
        "#0ne more advange of this batch_size, it reduces the some what training time\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "earlystopping = EarlyStopping(monitor='val_accuracy', patience=5, verbose=1, mode='auto', restore_best_weights=True)\n",
        "rlrop = ReduceLROnPlateau(monitor='val_accuracy', mode='max', patience=5, factor=0.5, min_lr=1e-6, verbose=1)\n",
        "from keras.optimizers import Adam\n",
        "callbacks = [earlystopping, rlrop]\n",
        "model.compile(optimizer=Adam(learning_rate = 0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(train_generator,batch_size=256, epochs=200, validation_data=validation_generator,callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E49gELPRv5Wl",
        "outputId": "3b554e1d-f072-4fc6-85f3-d6e85b51b198"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "126/126 [==============================] - 167s 1s/step - loss: 0.6529 - accuracy: 0.6418 - val_loss: 0.8426 - val_accuracy: 0.4998 - lr: 0.0010\n",
            "Epoch 2/200\n",
            "126/126 [==============================] - 145s 1s/step - loss: 0.6388 - accuracy: 0.6337 - val_loss: 0.8412 - val_accuracy: 0.4998 - lr: 0.0010\n",
            "Epoch 3/200\n",
            "126/126 [==============================] - 148s 1s/step - loss: 0.5536 - accuracy: 0.7245 - val_loss: 0.8764 - val_accuracy: 0.5818 - lr: 0.0010\n",
            "Epoch 4/200\n",
            "126/126 [==============================] - 154s 1s/step - loss: 0.4847 - accuracy: 0.7744 - val_loss: 1.3323 - val_accuracy: 0.5843 - lr: 0.0010\n",
            "Epoch 5/200\n",
            "126/126 [==============================] - 150s 1s/step - loss: 0.4139 - accuracy: 0.8130 - val_loss: 0.5984 - val_accuracy: 0.7237 - lr: 0.0010\n",
            "Epoch 6/200\n",
            "126/126 [==============================] - 150s 1s/step - loss: 0.3544 - accuracy: 0.8437 - val_loss: 0.4750 - val_accuracy: 0.8216 - lr: 0.0010\n",
            "Epoch 7/200\n",
            "126/126 [==============================] - 146s 1s/step - loss: 0.3036 - accuracy: 0.8721 - val_loss: 1.3786 - val_accuracy: 0.6535 - lr: 0.0010\n",
            "Epoch 8/200\n",
            "126/126 [==============================] - 152s 1s/step - loss: 0.2573 - accuracy: 0.8928 - val_loss: 3.7116 - val_accuracy: 0.5141 - lr: 0.0010\n",
            "Epoch 9/200\n",
            "126/126 [==============================] - 153s 1s/step - loss: 0.2815 - accuracy: 0.8771 - val_loss: 0.2753 - val_accuracy: 0.8868 - lr: 0.0010\n",
            "Epoch 10/200\n",
            "126/126 [==============================] - 153s 1s/step - loss: 0.2717 - accuracy: 0.8832 - val_loss: 0.2770 - val_accuracy: 0.8888 - lr: 0.0010\n",
            "Epoch 11/200\n",
            "126/126 [==============================] - 151s 1s/step - loss: 0.2069 - accuracy: 0.9136 - val_loss: 0.2463 - val_accuracy: 0.9006 - lr: 0.0010\n",
            "Epoch 12/200\n",
            "126/126 [==============================] - 151s 1s/step - loss: 0.1793 - accuracy: 0.9263 - val_loss: 0.2966 - val_accuracy: 0.8987 - lr: 0.0010\n",
            "Epoch 13/200\n",
            "126/126 [==============================] - 151s 1s/step - loss: 0.1916 - accuracy: 0.9222 - val_loss: 0.2840 - val_accuracy: 0.8997 - lr: 0.0010\n",
            "Epoch 14/200\n",
            "126/126 [==============================] - 148s 1s/step - loss: 0.1834 - accuracy: 0.9245 - val_loss: 0.4905 - val_accuracy: 0.7731 - lr: 0.0010\n",
            "Epoch 15/200\n",
            "126/126 [==============================] - 149s 1s/step - loss: 0.1710 - accuracy: 0.9308 - val_loss: 0.2041 - val_accuracy: 0.9155 - lr: 0.0010\n",
            "Epoch 16/200\n",
            "126/126 [==============================] - 145s 1s/step - loss: 0.1465 - accuracy: 0.9410 - val_loss: 0.1798 - val_accuracy: 0.9323 - lr: 0.0010\n",
            "Epoch 17/200\n",
            "126/126 [==============================] - 143s 1s/step - loss: 0.1328 - accuracy: 0.9477 - val_loss: 0.3238 - val_accuracy: 0.8680 - lr: 0.0010\n",
            "Epoch 18/200\n",
            "126/126 [==============================] - 145s 1s/step - loss: 0.1604 - accuracy: 0.9358 - val_loss: 0.1836 - val_accuracy: 0.9254 - lr: 0.0010\n",
            "Epoch 19/200\n",
            "126/126 [==============================] - 145s 1s/step - loss: 0.1246 - accuracy: 0.9517 - val_loss: 0.3203 - val_accuracy: 0.8942 - lr: 0.0010\n",
            "Epoch 20/200\n",
            "126/126 [==============================] - 144s 1s/step - loss: 0.1214 - accuracy: 0.9523 - val_loss: 0.2944 - val_accuracy: 0.9095 - lr: 0.0010\n",
            "Epoch 21/200\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.1073 - accuracy: 0.9563Restoring model weights from the end of the best epoch: 16.\n",
            "\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "126/126 [==============================] - 143s 1s/step - loss: 0.1073 - accuracy: 0.9563 - val_loss: 1.4936 - val_accuracy: 0.6846 - lr: 0.0010\n",
            "Epoch 21: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe6087c4c10>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#I used here earlystopping which is giving the best accuracy on test data 21st epoch\n",
        "#Test accuracy or validation accuracy is 93.23% and it is the best accuracy from all the models I have tried\n",
        "#Training accuracy is 94.10%\n"
      ],
      "metadata": {
        "id": "9JYqipmOy1fs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}